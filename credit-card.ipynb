{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed5e3f1-724b-4324-a2f1-1341c6d2a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2020-06-21 12:14:25  2291163933867244   \n",
      "1           1   2020-06-21 12:14:33  3573030041201292   \n",
      "2           2   2020-06-21 12:14:53  3598215285024754   \n",
      "3           3   2020-06-21 12:15:15  3591919803438423   \n",
      "4           4   2020-06-21 12:15:17  3526826139003047   \n",
      "\n",
      "                               merchant        category    amt   first  \\\n",
      "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
      "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
      "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
      "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
      "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
      "\n",
      "       last gender                       street  ...      lat      long  \\\n",
      "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
      "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
      "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
      "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
      "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
      "\n",
      "   city_pop                     job         dob  \\\n",
      "0    333497     Mechanical engineer  1968-03-19   \n",
      "1       302  Sales professional, IT  1990-01-17   \n",
      "2     34496       Librarian, public  1970-10-21   \n",
      "3     54767            Set designer  1987-07-25   \n",
      "4      1126      Furniture designer  1955-07-06   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
      "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
      "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
      "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
      "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
      "\n",
      "   is_fraud  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b420de61-ad61-4c65-b161-ad50a3267ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0               0\n",
      "trans_date_trans_time    0\n",
      "cc_num                   0\n",
      "merchant                 0\n",
      "category                 0\n",
      "amt                      0\n",
      "first                    0\n",
      "last                     0\n",
      "gender                   0\n",
      "street                   0\n",
      "city                     0\n",
      "state                    0\n",
      "zip                      0\n",
      "lat                      0\n",
      "long                     0\n",
      "city_pop                 0\n",
      "job                      0\n",
      "dob                      0\n",
      "trans_num                0\n",
      "unix_time                0\n",
      "merch_lat                0\n",
      "merch_long               0\n",
      "is_fraud                 0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Unnamed: 0             555719 non-null  int64  \n",
      " 1   trans_date_trans_time  555719 non-null  object \n",
      " 2   cc_num                 555719 non-null  int64  \n",
      " 3   merchant               555719 non-null  object \n",
      " 4   category               555719 non-null  object \n",
      " 5   amt                    555719 non-null  float64\n",
      " 6   first                  555719 non-null  object \n",
      " 7   last                   555719 non-null  object \n",
      " 8   gender                 555719 non-null  object \n",
      " 9   street                 555719 non-null  object \n",
      " 10  city                   555719 non-null  object \n",
      " 11  state                  555719 non-null  object \n",
      " 12  zip                    555719 non-null  int64  \n",
      " 13  lat                    555719 non-null  float64\n",
      " 14  long                   555719 non-null  float64\n",
      " 15  city_pop               555719 non-null  int64  \n",
      " 16  job                    555719 non-null  object \n",
      " 17  dob                    555719 non-null  object \n",
      " 18  trans_num              555719 non-null  object \n",
      " 19  unix_time              555719 non-null  int64  \n",
      " 20  merch_lat              555719 non-null  float64\n",
      " 21  merch_long             555719 non-null  float64\n",
      " 22  is_fraud               555719 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 97.5+ MB\n",
      "None\n",
      "is_fraud\n",
      "0    553574\n",
      "1      2145\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check dataset information\n",
    "print(df.info())\n",
    "\n",
    "# Check class distribution (fraud vs. non-fraud)\n",
    "print(df['is_fraud'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bc6e82f-71a4-4272-a9eb-0b8c7fb8a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Columns: ['Unnamed: 0', 'cc_num', 'amt', 'zip', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n",
      "Categorical Columns: ['trans_date_trans_time', 'merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'job', 'dob', 'trans_num']\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"Numeric Columns:\", list(numeric_cols))\n",
    "print(\"Categorical Columns:\", list(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e28a4e92-f274-4722-b1f9-e9f967134613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0               0\n",
      "trans_date_trans_time    0\n",
      "cc_num                   0\n",
      "merchant                 0\n",
      "category                 0\n",
      "amt                      0\n",
      "first                    0\n",
      "last                     0\n",
      "gender                   0\n",
      "street                   0\n",
      "city                     0\n",
      "state                    0\n",
      "zip                      0\n",
      "lat                      0\n",
      "long                     0\n",
      "city_pop                 0\n",
      "job                      0\n",
      "dob                      0\n",
      "trans_num                0\n",
      "unix_time                0\n",
      "merch_lat                0\n",
      "merch_long               0\n",
      "is_fraud                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing numerical values with median\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Check if there are any missing values left\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb6bd14c-a0f1-4fbf-aa09-a2765b6a8d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical encoding completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Apply Label Encoding for categorical columns\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_enc.fit_transform(df[col])\n",
    "\n",
    "print(\"Categorical encoding completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034c9d0b-5d9a-41c5-aa27-5cb2eb40b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category',\n",
      "       'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip',\n",
      "       'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
      "       'merch_lat', 'merch_long', 'is_fraud'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ede27a7-89db-419f-a55b-c4d68a15e784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime features extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Convert 'trans_date_trans_time' to datetime format\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "\n",
    "# Extract useful time-based features\n",
    "df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
    "df['month'] = df['trans_date_trans_time'].dt.month\n",
    "\n",
    "print(\"Datetime features extracted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f86a967-9b9a-4cf9-aef0-1dc39a5f7895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped unnecessary columns successfully!\n",
      "Index(['trans_date_trans_time', 'merchant', 'category', 'amt', 'gender',\n",
      "       'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'unix_time',\n",
      "       'merch_lat', 'merch_long', 'is_fraud', 'hour', 'day_of_week', 'month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(columns=['Unnamed: 0', 'first', 'last', 'street', 'city', 'trans_num', 'cc_num', 'dob'], inplace=True)\n",
    "\n",
    "print(\"Dropped unnecessary columns successfully!\")\n",
    "print(df.columns)  # To verify remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "342bde71-001d-442d-a7cd-20cc3f508b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud\n",
      "0    553574\n",
      "1      2145\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(df['is_fraud'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9945ad6a-4f75-4fa9-9aa2-23dd8a40e3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_date_trans_time    datetime64[ns]\n",
      "merchant                          int64\n",
      "category                          int64\n",
      "amt                             float64\n",
      "gender                            int64\n",
      "state                             int64\n",
      "zip                               int64\n",
      "lat                             float64\n",
      "long                            float64\n",
      "city_pop                          int64\n",
      "job                               int64\n",
      "unix_time                         int64\n",
      "merch_lat                       float64\n",
      "merch_long                      float64\n",
      "is_fraud                          int64\n",
      "hour                              int32\n",
      "day_of_week                       int32\n",
      "month                             int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "501a08cc-92a9-434a-bc13-d2c43dee85cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset balanced successfully! 🚀\n",
      "New class distribution: is_fraud\n",
      "0    553574\n",
      "1    276787\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Drop datetime column before SMOTE\n",
    "df = df.drop(columns=['trans_date_trans_time'])\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df.drop(columns=['is_fraud'])  # Features\n",
    "y = df['is_fraud']  # Target\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)  # Adjust ratio if needed\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"Dataset balanced successfully! 🚀\")\n",
    "print(\"New class distribution:\", y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "747dd2a4-f65e-4d6c-b954-f4aeeca8c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: (664288, 16)\n",
      "Testing Set Size: (166073, 16)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the datetime column (not useful for training)\n",
    "X = X_resampled\n",
    "y = y_resampled\n",
    "\n",
    "# Split into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training Set Size: {X_train.shape}\")\n",
    "print(f\"Testing Set Size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f2c88a1-2c02-4fa0-b9f7-0add388ae9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bf36329-a606-4e78-a550-80362b993268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (with increased iterations)\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c12306e-07ed-4a5a-a394-86a2718b2361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models trained successfully! ✅\n"
     ]
    }
   ],
   "source": [
    "# Train all models\n",
    "lr_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"All models trained successfully! ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29bab67b-e422-4292-b0ff-2afd2d4cb212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting classifier trained successfully! 🚀\n"
     ]
    }
   ],
   "source": [
    "# Create Voting Classifier with Hard Voting (majority vote)\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('rf', rf_model),\n",
    "        ('adaboost', adaboost_model),\n",
    "        ('gb', gb_model),\n",
    "        ('nb', nb_model)\n",
    "    ],\n",
    "    voting='hard'  # 'hard' uses majority voting, 'soft' uses probability\n",
    ")\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Voting classifier trained successfully! 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3854b307-63d0-40ea-95be-46beb423df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.9140\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94    110946\n",
      "           1       0.95      0.78      0.86     55127\n",
      "\n",
      "    accuracy                           0.91    166073\n",
      "   macro avg       0.93      0.88      0.90    166073\n",
      "weighted avg       0.92      0.91      0.91    166073\n",
      "\n",
      "Confusion Matrix:\n",
      " [[108657   2289]\n",
      " [ 12000  43127]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = voting_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Voting Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca4298c6-2da7-4442-b2d4-b98f71f84d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved successfully! 🎯\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained voting model\n",
    "with open(\"voting_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(voting_model, model_file)\n",
    "\n",
    "print(\"Trained model saved successfully! 🎯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc8e869-7b63-45d2-9dac-fab50475c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New Transaction Ready for Prediction!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example New Transaction (Manually Enter Values Based on Your Encoded Data)\n",
    "new_transaction = pd.DataFrame([{\n",
    "    'merchant': 10,  # Example encoded value (change based on your dataset)\n",
    "    'category': 3,   # Example encoded value\n",
    "    'amt': 120.50,\n",
    "    'gender': 1,     # Encoded (e.g., 0 = Male, 1 = Female)\n",
    "    'state': 5,      # Example encoded value\n",
    "    'zip': 12345,\n",
    "    'lat': 40.7128,\n",
    "    'long': -74.0060,\n",
    "    'city_pop': 8500000,\n",
    "    'job': 7,        # Example encoded value\n",
    "    'unix_time': 1.7e9,  # Example timestamp\n",
    "    'merch_lat': 40.7306,\n",
    "    'merch_long': -73.9352,\n",
    "    'hour': 14,\n",
    "    'day_of_week': 3,\n",
    "    'month': 6\n",
    "}])\n",
    "\n",
    "# Scale Numerical Features (Use the Same Scaler Used During Training)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling only on numerical features\n",
    "new_transaction[['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long', 'hour', 'day_of_week', 'month']] = scaler.fit_transform(\n",
    "    new_transaction[['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long', 'hour', 'day_of_week', 'month']])\n",
    "\n",
    "print(\"✅ New Transaction Ready for Prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da088d01-26ea-43c4-b41c-099367978738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# Load the trained model\n",
    "with open(\"voting_model.pkl\", \"rb\") as file:\n",
    "    voting_model = pickle.load(file)\n",
    "\n",
    "print(\"✅ Model Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e29eca-251b-4de6-a3d4-cfdc2f207d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transaction is Legitimate.\n"
     ]
    }
   ],
   "source": [
    "# Predict if the new transaction is fraud or not\n",
    "prediction = voting_model.predict(new_transaction)\n",
    "\n",
    "# Display the result\n",
    "if prediction[0] == 1:\n",
    "    print(\"🚨 ALERT: Fraudulent Transaction Detected! 🚨\")\n",
    "else:\n",
    "    print(\"✅ Transaction is Legitimate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "260d01a1-8716-471f-98ae-b47c473a7d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scaler Saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the scaler after fitting it on training data\n",
    "with open(\"scaler.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "print(\"✅ Scaler Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6da6419-22df-4b69-8942-36070b427970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Saved!\n"
     ]
    }
   ],
   "source": [
    "with open(\"voting_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(voting_model, model_file)\n",
    "\n",
    "print(\"✅ Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e90cfb8-e0d2-47a6-81e8-ba9e3763a5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and Scaler Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "import pickle\n",
    "with open(\"voting_model.pkl\", \"rb\") as file:\n",
    "    voting_model = pickle.load(file)\n",
    "\n",
    "# Load the saved scaler\n",
    "with open(\"scaler.pkl\", \"rb\") as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "print(\"✅ Model and Scaler Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646c2836-dec0-43f9-8fab-559225ba4617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New Transactions Ready for Prediction!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate multiple test transactions (modify as needed)\n",
    "new_transactions = pd.DataFrame([\n",
    "    {\n",
    "        'merchant': np.random.randint(1, 20),\n",
    "        'category': np.random.randint(1, 10),\n",
    "        'amt': round(np.random.uniform(1, 5000), 2),\n",
    "        'gender': np.random.choice([0, 1]),\n",
    "        'state': np.random.randint(1, 50),\n",
    "        'zip': np.random.randint(10000, 99999),\n",
    "        'lat': round(np.random.uniform(-90, 90), 6),\n",
    "        'long': round(np.random.uniform(-180, 180), 6),\n",
    "        'city_pop': np.random.randint(1000, 10000000),\n",
    "        'job': np.random.randint(1, 20),\n",
    "        'unix_time': np.random.randint(1.5e9, 1.8e9),\n",
    "        'merch_lat': round(np.random.uniform(-90, 90), 6),\n",
    "        'merch_long': round(np.random.uniform(-180, 180), 6),\n",
    "        'hour': np.random.randint(0, 24),\n",
    "        'day_of_week': np.random.randint(0, 7),\n",
    "        'month': np.random.randint(1, 12)\n",
    "    }\n",
    "    for _ in range(10)  # Generate 10 random transactions\n",
    "])\n",
    "\n",
    "# Scale the numerical features using the preloaded scaler\n",
    "numerical_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long', 'hour', 'day_of_week', 'month']\n",
    "new_transactions[numerical_features] = scaler.transform(new_transactions[numerical_features])\n",
    "\n",
    "print(\"✅ New Transactions Ready for Prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e72659e2-535a-44b3-86f4-b58bf4774ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       amt  category  fraud_prediction\n",
      "0  4736.85         3                 1\n",
      "1  1660.69         1                 0\n",
      "2  2073.96         1                 0\n",
      "3    32.38         8                 0\n",
      "4  1916.90         5                 0\n",
      "5  3272.46         5                 0\n",
      "6    72.85         3                 0\n",
      "7  4071.24         1                 0\n",
      "8  1968.97         1                 0\n",
      "9  2400.17         3                 0\n",
      "🚨 Fraudulent Transactions Detected: 1\n",
      "✅ Legitimate Transactions: 9\n"
     ]
    }
   ],
   "source": [
    "# Predict fraud or not\n",
    "predictions = voting_model.predict(new_transactions)\n",
    "\n",
    "# Add predictions to the DataFrame\n",
    "new_transactions['fraud_prediction'] = predictions\n",
    "\n",
    "# Display results\n",
    "print(new_transactions[['amt', 'category', 'fraud_prediction']])\n",
    "\n",
    "# Count fraud vs non-fraud cases\n",
    "fraud_count = (new_transactions['fraud_prediction'] == 1).sum()\n",
    "legit_count = (new_transactions['fraud_prediction'] == 0).sum()\n",
    "\n",
    "print(f\"🚨 Fraudulent Transactions Detected: {fraud_count}\")\n",
    "print(f\"✅ Legitimate Transactions: {legit_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a51a077-97fb-4ffc-8658-8b36467915c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10 real test transactions\n",
    "real_transactions = X_test.sample(10, random_state=42)  # Random selection\n",
    "real_labels = y_test.loc[real_transactions.index]  # Get actual fraud labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "388b57e4-641d-41e3-851f-6c6e5232e235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               amt  category  predicted_fraud  actual_fraud\n",
      "221390   11.120000         1                0             0\n",
      "563007  545.095319         6                1             1\n",
      "807610  114.101080         4                0             1\n",
      "203865    3.940000        12                0             0\n",
      "374963   27.960000        10                0             0\n",
      "219961    6.880000        11                0             0\n",
      "496519    2.650000         8                0             0\n",
      "93985    74.200000         2                0             0\n",
      "757062  330.312604         4                1             1\n",
      "457034   78.710000         5                0             0\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on real test transactions\n",
    "real_predictions = voting_model.predict(real_transactions)\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "real_transactions['predicted_fraud'] = real_predictions\n",
    "real_transactions['actual_fraud'] = real_labels\n",
    "\n",
    "# Display results\n",
    "print(real_transactions[['amt', 'category', 'predicted_fraud', 'actual_fraud']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f1ad8b9-ec41-410e-a4a4-f13941fc56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Evaluation on Real Transactions\n",
      "Accuracy: 0.9000\n",
      "Precision: 1.0000\n",
      "Recall: 0.6667\n",
      "F1 Score: 0.8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7 0]\n",
      " [1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "accuracy = accuracy_score(real_labels, real_predictions)\n",
    "precision = precision_score(real_labels, real_predictions)\n",
    "recall = recall_score(real_labels, real_predictions)\n",
    "f1 = f1_score(real_labels, real_predictions)\n",
    "\n",
    "print(f\"✅ Model Evaluation on Real Transactions\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(real_labels, real_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc1d96-6b24-4fd0-bb05-f891c9357b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
